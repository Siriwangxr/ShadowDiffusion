name: joint_tune_sam+diffusion
version: joint_mse+1tv+1e-1constrain_1e-5_v1
phase: test
samshadow_ckpt_path: ./
save_result_path: ./

tv_loss_beta: 1
grad_loss_weight: 0.1
loss_type: mse+tv+constrain


datasets:
  train:
    name: SRD_sam_train
    mode: HR
    dataroot: ./dataset/SRD_sam_mask_B/train
    gt_mask_dir: /home/xinrui/projects/ShadowDiffusion/dataset/SRD_sam_mask_B/train/division_filter_results
    batch_size: 2
    val_data_len: 4
    num_workers: 8
    use_shuffle: true
  test:
    name: SRD_sam_val
    mode: LRHR
    dataroot: ./dataset/SRD_sam_mask_B/test
    gt_mask_dir: /home/xinrui/projects/ShadowDiffusion/dataset/SRD_sam_mask_B/test/division_filter_results
    data_len: -1
    batch_size: 1

model:
  which_model_G: sr3
  unet:
    in_channel: 7
    out_channel: 3
    inner_channel: 64
    norm_groups: 16
    channel_multiplier:
      - 1
      - 2
      - 4
      - 8
    attn_res:
      - 16
    res_blocks: 2
    dropout: 0
  beta_schedule:
    train:
      schedule: linear
      n_timestep: 1000
      linear_start: 1e-4
      linear_end: 0.02
    val:
      schedule: linear
      n_timestep: 1000
      linear_start: 1e-4
      linear_end: 0.02
  diffusion:
    image_size: 512
    channels: 3
    conditional: true

#sam:
#  input_size: 1024
#  loss: iou

train:
  gpu_ids: [0, 1, 2, 3]
  accumulate_grad_batches: 2
  max_epochs: 500
  every_n_epochs: 100
  optimizer:
    lr: 1e-5

test:
  gpu_ids: [0]

warmup_epochs: 10


ckpt_path:
#  'lora_sam': /home/xinrui/projects/ShadowDiffusion/experiments_lightning/tune_sam/lora_mseloss_1tvloss_1e-1contGradloss_version_7/epoch=99.ckpt
  'ddpm': ./experiments/official_test/checkpoint/SRD_dataset/I2130000_E12080 # two ckpts share same name
  'SAM':  "./experiments/official_test/SAM_ckpt/sam_vit_h_4b8939.pth"

#  ./experiments_lightning/tune_sam/lora_mseloss_version_1/epoch=49.ckpt

bbox_path: "./dataset/SRD_sam_mask_B/train/bounding_boxes_DHAN.yaml"
test_bbox_path: "./dataset/SRD_sam_mask_B/test/bounding_boxes_DHAN.yaml"
model_type: "vit_h"
sam_rank: 8